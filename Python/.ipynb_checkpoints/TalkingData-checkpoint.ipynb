{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TalkingData AdTracking Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was taken from the __[“TalkingData AdTracking Fraud Detection Challenge”](https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection)__ on\n",
    "Kaggle. The host company, TalkingData, is China’s largest independent big data service\n",
    "platform. It covers over 70% of active mobile devices nationwide and handles 3 billion clicks\n",
    "per day, most of which are potentially fraudulent.<br> \n",
    "For this challenge, our goal was to build an\n",
    "algorithm that predicts whether a user will download an application after clicking a mobile\n",
    "advertisement.\n",
    "<br><br>\n",
    "We'll start by reading in the data (data files can be downloaded __[here](https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/data)__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries for the project\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics, cross_validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to the data folder\n",
    "DATA_PATH = r\"C:\\Users\\reio\\Documents\\GitHub\\data-science-portfolio\\TalkingData\\data\"\n",
    "\n",
    "# Function to load in data\n",
    "def load_data(data_path=DATA_PATH):\n",
    "    # PATHS TO FILE\n",
    "    train_path = os.path.join(data_path, \"train.csv\")\n",
    "    test_path = os.path.join(data_path, \"test.csv\")\n",
    "\n",
    "    return pd.read_csv(train_path), pd.read_csv(test_path)\n",
    "\n",
    "# Load in train and test sets\n",
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "The dataset that TalkingData had provided covers approximately 200 million clicks. The whole dataset, which was ordered by timestamps, was split into the train set, whose first click began on 2017-11-06, and the test set, whose first click began on 2017-11-10. The train set covers all the clicks during a 3-day period, and the test set covers all the clicks on the next day.<br>\n",
    "\n",
    "### Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Take a look at the train set ###\n",
    "print(train.head())\n",
    "# Describe train\n",
    "print(train.dtypes)\n",
    "print(train.max())\n",
    "\n",
    "### Take a look at the test set ###\n",
    "print(test.head())\n",
    "# Describe train\n",
    "print(test.dtypes)\n",
    "print(test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 features are included in train data set.<br>\n",
    "The test set contains only 7 features, with the exception of **is_attributed**, which is the\n",
    "binary response variable that needs to be predicted, and **attributed_time**. The test set\n",
    "also contains an ID column to identify each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(train.isnull().sum())\n",
    "# Extract data where is_attributed == 1\n",
    "train_att = train[train['is_attributed']==1]\n",
    "# Check NAs\n",
    "print(train_att.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the **attributed_time** feature, we found most of the observations to be missing.\n",
    "However, this was due to the fact that most of the clicks did not convert into downloads (i.e.\n",
    "**is_attributed** equals 0). This feature is only available when a click was converted into a\n",
    "download, which is also why it was missing in the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Percentage of is_attributed == 1\n",
    "p = len(train_att)/len(train)\n",
    "print(len(train_att))\n",
    "print('The percentage of converted clicks is {num:.10%}'.format(num=p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is highly imbalanced, with 99.75% of the observations belonging to the negative class and only 0.25% of the observations in the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the proportion of clicks that converted into a download or not\n",
    "plt.figure(figsize=(6,6))\n",
    "#sns.set(font_scale=1.2)\n",
    "mean = (train.is_attributed.values == 1).mean()\n",
    "ax = sns.barplot(['Converted (1)', 'Not Converted (0)'], [mean, 1-mean])\n",
    "ax.set(ylabel='Proportion', title='Proportion of clicks converted into app downloads')\n",
    "for p, uniq in zip(ax.patches, [mean, 1-mean]):\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height+0.01,\n",
    "            '{}%'.format(round(uniq * 100, 2)),\n",
    "            ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For IP 6\n",
    "ip_6 = train[train['ip'] == 6]\n",
    "print(ip_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature **ip** contains different IP addresses. However, it may not be appropriate\n",
    "to treat each IP as a unique value. Firstly, IP addresses are easily generated, and\n",
    "we would not be able to recognize a real IP from a fake one. <br>\n",
    "We can see that a single IP can be associated with different devices on different operating systems,\n",
    "implying that the IP address could have been representative of a network address. This\n",
    "was a motivation to treat the aggregated feature **ip_device_os** as one single user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspecting behaviors of click_time and attributed_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**click_time** and **attributed_time** have the same patterns.\n",
    "Along with the fact that most of **attributed_time** is N/A, it seems reasonable to drop the **attributed_time** feature and only extract information from the **click_time** feature. <br><br>\n",
    "As the behaviors of the converted and non-converted clicks are possibly different, let's take a look at the conversion rate, which is the proportion of download counts over the total click counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Behavior of click_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a seasonal behavior in **click_time** on a daily basis, so it's reasonable for\n",
    "us to use **hour** and **wday** (day of the week) as new features in data analysis. Since our data\n",
    "only covers a 4-day span, the year, month, or week are all the same for all observations,\n",
    "so we don't need these in prediction, and **click_time** feature is dropped after\n",
    "necessary information has been extracted.\n",
    "\n",
    "### Data-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features from click_time\n",
    "def ppClicktime(df):\n",
    "    df['click_time'] = pd.to_datetime(df['click_time'])\n",
    "    df['wday'] = df['click_time'].dt.dayofweek\n",
    "    df['hour'] = df['click_time'].dt.hour\n",
    "    return df\n",
    "\n",
    "# Pre-processed training and testing sets\n",
    "train_pp = ppClicktime(train)\n",
    "test_pp = ppClicktime(test)\n",
    "\n",
    "# Drop click_time\n",
    "train_pp.drop('click_time', axis = 1, inplace = True)\n",
    "test_pp.drop('click_time', axis = 1, inplace = True)\n",
    "\n",
    "# Drop attributed_time\n",
    "train_pp.drop('attributed_time', axis = 1, inplace = True)\n",
    "\n",
    "# Write to csv\n",
    "train_pp.to_csv(os.path.join(data_path,\"train_pp.csv\"),index=None)\n",
    "test_pp.to_csv(os.path.join(data_path,\"test_pp.csv\"),index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is highly imbalanced, as described in the previous section. In classification\n",
    "problems, most classifiers like logistic regression and decision tree work best when the class\n",
    "distribution of the response variable in the dataset is balanced. However, in real world\n",
    "problems, like fraud detection, the datasets are often highly imbalanced and it would be\n",
    "difficult to derive a meaningful and good predictive model, due to the lack of information\n",
    "of the minority class. <br><br>\n",
    "There are two popular solutions to deal with imbalanced data:\n",
    "oversampling or undersampling. Considering the nature of this dataset (high number of\n",
    "observations, which would require a lot of computing power), we'd go with the undersampling\n",
    "method, which randomly discards majority samples (negative observations in\n",
    "is attributed) to achieve equal distribution with the minority class (positive observations\n",
    "in is attributed). <br><br>\n",
    "However, this means that we're potentially losing useful information in our original train\n",
    "dataset. Therefore, we'll also perform our modeling methods on two other subsets, including\n",
    "the first 10 or 50 million observations in the given train set. Even if these subsets are\n",
    "still imbalanced, we're hoping to extract some useful information, while still keeping the\n",
    "computation capabilities in check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create balanced train set ###\n",
    "\n",
    "# Separate the 2 classes\n",
    "t0 = train_pp[train_pp['is_attributed'] == 0]\n",
    "t1 = train_pp[train_pp['is_attributed'] == 1]\n",
    "\n",
    "# Undersample class 0 (without replacement)\n",
    "t0_udsp = resample(t0, replace=False, n_samples=len(t1), random_state=142) \n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "train_1m = pd.concat([t0_udsp, t1])\n",
    " \n",
    "# Display new class counts\n",
    "print(train_1m.is_attributed.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load in the first ssize rows of pre-processed train data\n",
    "def load_train_pp(data_path=DATA_PATH,ssize):\n",
    "    train_pp_path = os.path.join(data_path, \"train_pp.csv\")\n",
    "    return pd.read_csv(train_pp_path,nrows=ssize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load in pre-processed train subset with the first 10 million observations ###\n",
    "train_10m = load_train_pp(ssize=10000000)\n",
    "train_50m = load_train_pp(ssize=50000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the latent information of the conversion rate, we'll aggregate the training data\n",
    "on different groups of features. I tried several combinations of two-way and three-way\n",
    "interactions. For example, feature **ip_os_count** means that we grouped the data by **ip** and\n",
    "**os** and count the number of clicks. I paid close attention to the features aggregated on\n",
    "hour, as this might be an important feature, and those that were aggregated on\n",
    "hour proved to be significant in our models. After trying all possible combinations, our final\n",
    "predictive model includes 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to add new aggregated features\n",
    "def aggregate_features(df):\n",
    "    # IPs\n",
    "    n_ip = df[['ip','channel']].groupby(by=['ip'])[['channel']].count().reset_index().rename(index = str, columns={'channel': 'n_ip'})\n",
    "    df = df.merge(n_ip, on = ['ip'], how = 'left')\n",
    "    # app count\n",
    "    ip_app_count = df[['ip','app', 'channel']].groupby(by=['ip', 'app'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_app_count'})\n",
    "    df = df.merge(ip_app_count, on = ['ip', 'app'], how = 'left')\n",
    "    # device count\n",
    "    ip_device_count = df[['ip','device', 'channel']].groupby(by=['ip', 'device'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_device_count'})\n",
    "    df = df.merge(ip_device_count, on = ['ip', 'device'], how = 'left')\n",
    "    # os count\n",
    "    ip_os_count = df[['ip','os', 'channel']].groupby(by=['ip', 'os'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_os_count'})\n",
    "    df = df.merge(ip_os_count, on = ['ip', 'os'], how = 'left')\n",
    "    # wday + hour\n",
    "    ip_wday_hour = df[['ip', 'wday', 'hour', 'channel']].groupby(by = ['ip','wday','hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_wday_hour'})\n",
    "    df = df.merge(ip_wday_hour, on = ['ip', 'wday', 'hour'], how = 'left')\n",
    "    # app + hour\n",
    "    ip_app_hour = df[['ip', 'app', 'hour', 'channel']].groupby(by = ['ip','app','hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_app_hour'})\n",
    "    df = df.merge(ip_app_hour, on = ['ip', 'app', 'hour'], how = 'left')\n",
    "    # device + hour\n",
    "    ip_device_hour = df[['ip', 'device', 'hour', 'channel']].groupby(by = ['ip','device','hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_device_hour'})\n",
    "    df = df.merge(ip_device_hour, on = ['ip', 'device', 'hour'], how = 'left')\n",
    "    # os + hour\n",
    "    ip_os_hour = df[['ip', 'os', 'hour', 'channel']].groupby(by = ['ip','os','hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_os_hour'})\n",
    "    df = df.merge(ip_os_hour, on = ['ip', 'os', 'hour'], how = 'left')\n",
    "    # os + device + hour\n",
    "    ip_os_device_hour = df[['ip', 'os', 'device', 'hour', 'channel']].groupby(by = ['ip','os', 'device', 'hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_os_device_hour'})\n",
    "    df = df.merge(ip_os_device_hour, on = ['ip', 'os', 'device', 'hour'], how = 'left')\n",
    "    # app + device + hour\n",
    "    ip_app_device_hour = df[['ip', 'app', 'device', 'hour', 'channel']].groupby(by = ['ip','app', 'device', 'hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_app_device_hour'})\n",
    "    df = df.merge(ip_app_device_hour, on = ['ip', 'app', 'device', 'hour'], how = 'left')\n",
    "    # device + os\n",
    "    ip_os_device = df[['ip', 'os', 'device', 'channel']].groupby(by = ['ip','os', 'device'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_os_device'})\n",
    "    df = df.merge(ip_os_device, on = ['ip', 'os', 'device'], how = 'left')\n",
    "    # app + device\n",
    "    ip_app_device = df[['ip', 'app', 'device', 'channel']].groupby(by = ['ip','app', 'device'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_app_device'})\n",
    "    df = df.merge(ip_app_device, on = ['ip', 'app', 'device'], how = 'left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the correlation matrix of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Aggregate data (full dataset)\n",
    "#train_ag = aggregate_features(train_pp)\n",
    "test_ag = aggregate_features(test_pp)\n",
    "## Write to csv\n",
    "#train_ag.to_csv(\"train_ag.csv\",index=None)\n",
    "#test_ag.to_csv(\"test_ag.csv\",index=None)\n",
    "\n",
    "# 1 million subset\n",
    "train_1m_ag = aggregate_features(train_1m)\n",
    "# 10 million subset\n",
    "train_10m_ag = aggregate_features(train_10m)\n",
    "# 50 million subset\n",
    "train_50m_ag = aggregate_features(train_50m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop **ip** since we are not going to use this feature in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1m_ag = train_1m_ag.drop(['ip'],axis=1)\n",
    "train_10m_ag = train_10m_ag.drop(['ip'],axis=1)\n",
    "train_50m_ag = train_50m_ag.drop(['ip'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Methods\n",
    "### Logistic Regression\n",
    "Let's first perform Logistic Regression (with 5-fold cross-validation) on our balanced train data. Since our data is sparse, we'll apply a LASSO regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate response variables from predictors\n",
    "y = list(train_1m_ag.is_attributed)\n",
    "X = train_1m_ag.drop(['is_attributed'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "y_pred = cross_validation.cross_val_predict(logreg, X, y, cv=5)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest\n",
    "Logistic Regression did not give very good results. Let's try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest model\n",
    "Ntree = 500\n",
    "rfc = RandomForestClassifier(n_estimators=Ntree)\n",
    "y_pred = cross_validation.cross_val_predict(rfc, X, y, cv=5)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LightGBM\n",
    "Both Logistic Regression and Random Forest did not give good results, so we will try LightGBM, which is a Gradient Boosting Decision Tree (GBDT) algorithm that has been widely used in recent years, especially in Kaggle competitions. GBDT methods, especially LightGBM, have proved their efficiency and accuracy over common ensemble techniques like random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the LightGBM model parameters\n",
    "target = 'is_attributed'\n",
    "predictors = ['device', 'app', 'os', 'channel', 'wday', 'hour',\n",
    "              'n_ip', 'ip_app_count', 'ip_device_count', 'ip_os_count',\n",
    "              'ip_wday_hour', 'ip_app_hour', 'ip_device_hour', \n",
    "              'ip_os_hour', 'ip_os_device_hour']\n",
    "categorical = ['app', 'device', 'os', 'channel', 'wday', 'hour']\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 255,  \n",
    "        'max_depth': 8,  \n",
    "        'min_child_samples': 100,  \n",
    "        'max_bin': 100,  \n",
    "        'subsample': 0.7,  \n",
    "        'subsample_freq': 1,  \n",
    "        'colsample_bytree': 0.7,  \n",
    "        'min_child_weight': 0,  \n",
    "        'subsample_for_bin': 200000,  \n",
    "        'min_split_gain': 0,  \n",
    "        'reg_alpha': 0,  \n",
    "        'reg_lambda': 0,  \n",
    "        # 'nthread': 8,\n",
    "        'verbose': 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the lightGBM model\n",
    "def lgb_train(X_train, X_val, y_train, y_val):\n",
    "    # Model\n",
    "    dtrain = lgb.Dataset(X_train[predictors].values, label=y_train,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "    dvalid = lgb.Dataset(X_val[predictors].values, label=y_val,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "    lgb_model = lgb.train(params, \n",
    "                 dtrain, \n",
    "                 valid_sets=[dtrain, dvalid], \n",
    "                 valid_names=['train','valid'], \n",
    "                 evals_result=evals_results, \n",
    "                 num_boost_round=350,\n",
    "                 early_stopping_rounds=30,\n",
    "                 verbose_eval=True, \n",
    "                 feval=None)\n",
    "    return lgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's first try it on the 10 million dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate response variables from predictors\n",
    "y = list(train_10m_ag.is_attributed)\n",
    "X = train_10m_ag.drop(['is_attributed'],axis=1)\n",
    "# Split the training data into training and validation sets for cross-validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train LightGBM model\n",
    "lgb_model = lgb_train(X_train, X_val, y_train, y_val)\n",
    "# Predict on test dataset and write out submission file\n",
    "test2 = test_ag.drop(['click_id','ip'],axis=1)\n",
    "y_submit = lgb_model.predict(test2[predictors],num_iteration=lgb_model.best_iteration)\n",
    "test_ag['is_attributed'] = y_submit\n",
    "ans = test_ag[['click_id', 'is_attributed']]\n",
    "ans.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it on the 50 million dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate response variables from predictors\n",
    "y = list(train_50m_ag.is_attributed)\n",
    "X = train_50m_ag.drop(['is_attributed'],axis=1)\n",
    "# Split the training data into training and validation sets for cross-validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train LightGBM model\n",
    "lgb_model = lgb_train(X_train, X_val, y_train, y_val)\n",
    "# Predict on test dataset and write out submission file\n",
    "test2 = test_ag.drop(['click_id','ip'],axis=1)\n",
    "y_submit = lgb_model.predict(test2[predictors],num_iteration=lgb_model.best_iteration)\n",
    "test_ag['is_attributed'] = y_submit\n",
    "ans = test_ag[['click_id', 'is_attributed']]\n",
    "ans.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion\n",
    "We've seen that the newly created features were correlated with one another, and some of the original features were correlated as well (device and os). This explains why logistic regression was not a good model choice, even with LASSO regularization. Tree-based models solve this high multicollinearity problem by constructing trees in a greedy manner and using all information from all the newly created features. LightGBM proved to be a more preferable method, both in time, memory efficiency and accuracy. <br><br>\n",
    "AUC score increased as we used more observations in training. I tried to deal with the imbalanced data problem in our training dataset by creating a balanced undersampled train dataset. However, this left us with very little information, as most of the majority samples were discarded. Thus, using more samples and adjusting for the weight of the minority class in the GBDT methods resulted in better accuracys. This was another advantage of GBDT that was not possible in methods like logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
