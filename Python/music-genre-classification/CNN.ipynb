{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = []\n",
    "with open(\"df\", 'rb') as f:\n",
    "    content = f.read()\n",
    "    df = pickle.loads(content)\n",
    "df = np.asarray(df).astype(np.float32)\n",
    "\n",
    "m,n,o,p = df.shape\n",
    "\n",
    "df = df.reshape((df.shape[0], n*o*p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "with open(\"labels\", 'rb') as f:\n",
    "    content = f.read()\n",
    "    labels = pickle.loads(content)\n",
    "    labels = pd.get_dummies(labels)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 700\n",
    "batch_size = 64\n",
    "display_step = 10\n",
    "train_size = math.floor(m*0.8)\n",
    "\n",
    "# Network Parameters\n",
    "n_input = n * o * p\n",
    "n_classes = 10\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4654 118 13 11\n"
     ]
    }
   ],
   "source": [
    "print(m,n,o,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "permutation = np.random.permutation(len(df))\n",
    "df = df[permutation]\n",
    "labels = labels[permutation]\n",
    "\n",
    "# Split Train/Test\n",
    "traindf = df[:train_size]\n",
    "trainLabels = labels[:train_size]\n",
    "\n",
    "testdf = df[train_size:]\n",
    "testLabels = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def max_pool(sound, k):\n",
    "    return tf.nn.max_pool(sound, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_net(_X, _weights, _biases, _dropout):\n",
    "    # Reshape input\n",
    "    _X = tf.reshape(_X, shape=[-1, n, o, p])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(_X, _weights['wc1'], _biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = max_pool(conv1, k=2)\n",
    "    # Apply Dropout\n",
    "    #conv1 = tf.nn.dropout(conv1, _dropout)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, _weights['wc2'], _biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = max_pool(conv2, k=2)\n",
    "    # Apply Dropout\n",
    "    #conv2 = tf.nn.dropout(conv2, _dropout)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv3 output to fit dense layer input\n",
    "    dense1 = tf.reshape(conv2, [-1, _weights['wd1'].get_shape().as_list()[0]])\n",
    "    # Relu activation\n",
    "    dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, _weights['wd1']), _biases['bd1']))\n",
    "    # Apply Dropout\n",
    "    dense1 = tf.nn.dropout(dense1, _dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(dense1, _weights['out']), _biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 2x2 conv, p input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([2, 2, p, 32])),\n",
    "    # 2x2 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([2, 2, 32, 64])),\n",
    "    # fully connected, 30*4*64 inputs, 2^10 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([30*4*64, 1024])),\n",
    "    # 2^10 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])+0.01),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])+0.01),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])+0.01),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes])+0.01)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:batch_size]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 8413034.0000, Training Accuracy= 0.062\n",
      "Step 10, Minibatch Loss= 4974771.5000, Training Accuracy= 0.328\n",
      "Step 20, Minibatch Loss= 5123604.0000, Training Accuracy= 0.266\n",
      "Step 30, Minibatch Loss= 2797080.5000, Training Accuracy= 0.391\n",
      "Step 40, Minibatch Loss= 2769429.0000, Training Accuracy= 0.359\n",
      "Step 50, Minibatch Loss= 2193551.2500, Training Accuracy= 0.391\n",
      "Step 60, Minibatch Loss= 2525865.5000, Training Accuracy= 0.328\n",
      "Step 70, Minibatch Loss= 1644925.5000, Training Accuracy= 0.469\n",
      "Step 80, Minibatch Loss= 1796220.3750, Training Accuracy= 0.406\n",
      "Step 90, Minibatch Loss= 1771050.0000, Training Accuracy= 0.438\n",
      "Step 100, Minibatch Loss= 1700742.0000, Training Accuracy= 0.359\n",
      "Step 110, Minibatch Loss= 1703810.8750, Training Accuracy= 0.375\n",
      "Step 120, Minibatch Loss= 1683934.8750, Training Accuracy= 0.375\n",
      "Step 130, Minibatch Loss= 1264360.5000, Training Accuracy= 0.438\n",
      "Step 140, Minibatch Loss= 1327556.2500, Training Accuracy= 0.359\n",
      "Step 150, Minibatch Loss= 1130590.0000, Training Accuracy= 0.359\n",
      "Step 160, Minibatch Loss= 1385343.5000, Training Accuracy= 0.344\n",
      "Step 170, Minibatch Loss= 590799.7500, Training Accuracy= 0.625\n",
      "Step 180, Minibatch Loss= 782723.4375, Training Accuracy= 0.438\n",
      "Step 190, Minibatch Loss= 899598.5000, Training Accuracy= 0.453\n",
      "Step 200, Minibatch Loss= 872250.7500, Training Accuracy= 0.391\n",
      "Step 210, Minibatch Loss= 609490.0625, Training Accuracy= 0.500\n",
      "Step 220, Minibatch Loss= 641682.1250, Training Accuracy= 0.438\n",
      "Step 230, Minibatch Loss= 874048.7500, Training Accuracy= 0.453\n",
      "Step 240, Minibatch Loss= 638088.2500, Training Accuracy= 0.422\n",
      "Step 250, Minibatch Loss= 583419.3750, Training Accuracy= 0.547\n",
      "Step 260, Minibatch Loss= 635806.0000, Training Accuracy= 0.469\n",
      "Step 270, Minibatch Loss= 817630.1250, Training Accuracy= 0.406\n",
      "Step 280, Minibatch Loss= 538521.2500, Training Accuracy= 0.391\n",
      "Step 290, Minibatch Loss= 553008.0625, Training Accuracy= 0.453\n",
      "Step 300, Minibatch Loss= 458147.9375, Training Accuracy= 0.500\n",
      "Step 310, Minibatch Loss= 410911.9375, Training Accuracy= 0.406\n",
      "Step 320, Minibatch Loss= 423266.9375, Training Accuracy= 0.469\n",
      "Step 330, Minibatch Loss= 401660.0625, Training Accuracy= 0.453\n",
      "Step 340, Minibatch Loss= 477117.2500, Training Accuracy= 0.469\n",
      "Step 350, Minibatch Loss= 232648.6875, Training Accuracy= 0.531\n",
      "Step 360, Minibatch Loss= 230435.1875, Training Accuracy= 0.594\n",
      "Step 370, Minibatch Loss= 221335.1250, Training Accuracy= 0.547\n",
      "Step 380, Minibatch Loss= 250825.7188, Training Accuracy= 0.516\n",
      "Step 390, Minibatch Loss= 243818.1875, Training Accuracy= 0.531\n",
      "Step 400, Minibatch Loss= 266758.1875, Training Accuracy= 0.438\n",
      "Step 410, Minibatch Loss= 228191.5312, Training Accuracy= 0.375\n",
      "Step 420, Minibatch Loss= 187132.6250, Training Accuracy= 0.609\n",
      "Step 430, Minibatch Loss= 227132.0312, Training Accuracy= 0.578\n",
      "Step 440, Minibatch Loss= 286598.8750, Training Accuracy= 0.500\n",
      "Step 450, Minibatch Loss= 233150.9062, Training Accuracy= 0.531\n",
      "Step 460, Minibatch Loss= 166811.3438, Training Accuracy= 0.531\n",
      "Step 470, Minibatch Loss= 263291.5000, Training Accuracy= 0.547\n",
      "Step 480, Minibatch Loss= 301507.1562, Training Accuracy= 0.344\n",
      "Step 490, Minibatch Loss= 123507.5469, Training Accuracy= 0.562\n",
      "Step 500, Minibatch Loss= 182258.0312, Training Accuracy= 0.594\n",
      "Step 510, Minibatch Loss= 124778.3750, Training Accuracy= 0.562\n",
      "Step 520, Minibatch Loss= 160510.7656, Training Accuracy= 0.547\n",
      "Step 530, Minibatch Loss= 174230.2812, Training Accuracy= 0.516\n",
      "Step 540, Minibatch Loss= 155202.7031, Training Accuracy= 0.547\n",
      "Step 550, Minibatch Loss= 155041.9688, Training Accuracy= 0.516\n",
      "Step 560, Minibatch Loss= 197964.9219, Training Accuracy= 0.438\n",
      "Step 570, Minibatch Loss= 105828.0234, Training Accuracy= 0.500\n",
      "Step 580, Minibatch Loss= 121081.6172, Training Accuracy= 0.469\n",
      "Step 590, Minibatch Loss= 130680.9453, Training Accuracy= 0.516\n",
      "Step 600, Minibatch Loss= 106295.4531, Training Accuracy= 0.609\n",
      "Step 610, Minibatch Loss= 146763.5938, Training Accuracy= 0.438\n",
      "Step 620, Minibatch Loss= 92730.6250, Training Accuracy= 0.562\n",
      "Step 630, Minibatch Loss= 121661.1953, Training Accuracy= 0.453\n",
      "Step 640, Minibatch Loss= 96876.7500, Training Accuracy= 0.578\n",
      "Step 650, Minibatch Loss= 159532.2969, Training Accuracy= 0.484\n",
      "Step 660, Minibatch Loss= 86237.6328, Training Accuracy= 0.531\n",
      "Step 670, Minibatch Loss= 71258.2656, Training Accuracy= 0.547\n",
      "Step 680, Minibatch Loss= 95287.8281, Training Accuracy= 0.547\n",
      "Step 690, Minibatch Loss= 92698.9375, Training Accuracy= 0.516\n",
      "Step 700, Minibatch Loss= 113800.7812, Training Accuracy= 0.438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4189044\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    \n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = next_batch(batch_size, traindf, trainLabels)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.7})\n",
    "        #sess.run(train_op, feed_dict={X: traindf, Y: trainLabels, keep_prob: 1.})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.7})\n",
    "            #loss, acc = sess.run([cost, accuracy], feed_dict={X: traindf, Y: trainLabels, keep_prob: 1.0})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    saver.save(sess, \"./mfcc_model\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: testdf, Y: testLabels, keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test = []\n",
    "with open(\"test\", 'rb') as f:\n",
    "    content = f.read()\n",
    "    test = pickle.loads(content)\n",
    "test = np.asarray(df).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.90631638e+01 -8.94353561e+01 -1.46558640e+02 ... -2.27098598e+01\n",
      "  -2.49863491e+01 -3.37332573e+01]\n",
      " [-1.00561394e+02 -1.07341621e+02 -1.26368607e+02 ...  2.38584924e+00\n",
      "  -7.65956020e+00 -7.83618069e+00]\n",
      " [-6.08147316e+01  1.16712656e+01  3.85840225e+01 ...  3.45299301e+01\n",
      "   1.72764149e+01  7.81008339e+00]\n",
      " ...\n",
      " [-9.94997711e+01 -1.28598160e+02 -1.51047226e+02 ... -1.35269022e+01\n",
      "  -7.14845419e+00 -4.67074299e+00]\n",
      " [-1.89628906e+02 -2.00777924e+02 -2.23441757e+02 ... -6.96538973e+00\n",
      "  -3.96023655e+00  1.88281909e-01]\n",
      " [-1.16509964e+02 -1.70851242e+02 -2.30140564e+02 ... -1.15974646e+01\n",
      "  -1.07387991e+01 -1.54411640e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mfcc_model\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,16874]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,16874], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-151b39d2248e>\", line 2, in <module>\n    X = tf.placeholder(tf.float32, [None, n_input])\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1734, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4923, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,16874]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,16874], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,16874]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,16874], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8be40743073c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./mfcc_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,16874]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,16874], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-151b39d2248e>\", line 2, in <module>\n    X = tf.placeholder(tf.float32, [None, n_input])\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1734, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4923, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ptngu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,16874]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,16874], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./mfcc_model\")\n",
    "    y_pred = sess.run(prediction, feed_dict = {X: test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
